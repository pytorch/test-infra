name: Test upload-benchmark-results

on:
  pull_request:
    paths:
      # GHA route
      - .github/scripts/benchmarks/*
      - .github/scripts/upload_benchmark_results.py
      - .github/actions/upload-benchmark-results/*
      # Reusable workflow route
      - .github/actions/gather-benchmark-metadata/*
      - .github/actions/gather-runners-info/*
      - .github/actions/gather-dependencies/*
      - .github/workflows/upload_benchmark_results.yml
      # The test workflow itself
      - .github/workflows/test_upload_benchmark_results.yml
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

jobs:
  test-upload-benchmark-results-gha:
    strategy:
      matrix:
        runner: [linux.2xlarge, macos-m1-stable]
    runs-on: ${{ matrix.runner }}
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Test upload the benchmark results
        uses: ./.github/actions/upload-benchmark-results
        with:
          benchmark-results-dir: .github/scripts/benchmark-results-dir-for-testing/v3
          schema-version: v3
          dry-run: true
          github-token: ${{ secrets.GITHUB_TOKEN }}

  test-gather-benchmark-info:
    uses: ./.github/workflows/test_gather_benchmark_info.yml

  test-upload-benchmark-results-reusable-workflow:
    needs: test-gather-benchmark-info
    uses: ./.github/workflows/upload_benchmark_results.yml
    permissions:
      id-token: write
      contents: read
    with:
      benchmark-artifact: benchmark-results
      benchmark-metadata: ${{ needs.test-gather-benchmark-info.outputs.benchmark-metadata }}
      runners-info: ${{ needs.test-gather-benchmark-info.outputs.runners-info }}
      dependencies: ${{ needs.test-gather-benchmark-info.outputs.dependencies }}
      schema-version: v3
      dry-run: true

  test-upload-benchmark-results-no-files-found-ignore:
    runs-on: linux.2xlarge
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Test upload the benchmark results
        uses: ./.github/actions/upload-benchmark-results
        with:
          # There is no benchmark results in this directory
          benchmark-results-dir: .github/scripts/benchmarks
          schema-version: v3
          dry-run: true
          github-token: ${{ secrets.GITHUB_TOKEN }}

  test-upload-benchmark-results-no-files-found-error:
    runs-on: linux.2xlarge
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Test upload the benchmark results
        id: upload
        continue-on-error: true
        uses: ./.github/actions/upload-benchmark-results
        with:
          # There is no benchmark results in this directory
          benchmark-results-dir: .github/scripts/benchmarks
          schema-version: v3
          dry-run: true
          if-no-files-found: error
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Check that the upload fails
        env:
          UPLOAD_STATUS: ${{ steps.upload.outcome }}
        shell: bash
        run: |
          if [[ "${UPLOAD_STATUS}" != "failure" ]]; then
            exit 1
          fi
