# Week of 2026-01-12 to 2026-01-19 (42)

### Auto Revert (6)

- [Revert "[CI] Update CuDNN from 9.10 to 9.15 for CUDA-12.8 tests (#172683)"](https://github.com/pytorch/pytorch/commit/6de3d154038d80c3c9612283cf69949a45ad0a03)
  - Reverted automatically by pytorch's autorevert, to avoid this behaviour add the tag autorevert: disable ([comment](https://github.com/pytorch/pytorch/pull/172683#issuecomment-3764941265))
- [Revert "make `addmm` aware of cublas backend selection: a simple fix for #172231 (#172340)"](https://github.com/pytorch/pytorch/commit/a93aa5a86511354a166ddc9fb5cf35d20a0f4878)
  - Reverted automatically by pytorch's autorevert, to avoid this behaviour add the tag autorevert: disable ([comment](https://github.com/pytorch/pytorch/pull/172340#issuecomment-3760845060))
- [Revert "[fx] Don't delete keys from previous metadata (#172317)"](https://github.com/pytorch/pytorch/commit/528909e00dec3d7b317f488de2bc4e52f2bce9c1)
  - Reverted automatically by pytorch's autorevert, to avoid this behaviour add the tag autorevert: disable ([comment](https://github.com/pytorch/pytorch/pull/172317#issuecomment-3756351338))
- [Revert "[ROCm] add hipsparseSpSV and hipsparseSpSM support for triangular solve (#171097)"](https://github.com/pytorch/pytorch/commit/643e8ca76ae8991d76a43070ef587061e3baca2b)
  - Reverted automatically by pytorch's autorevert, to avoid this behaviour add the tag autorevert: disable ([comment](https://github.com/pytorch/pytorch/pull/171097#issuecomment-3747389804))
- [Revert "Fix torch.nn.Buffer in compile (#172222)"](https://github.com/pytorch/pytorch/commit/5594090294ce2d8c4ae1574bdb2919364d569bc4)
  - Reverted automatically by pytorch's autorevert, to avoid this behaviour add the tag autorevert: disable ([comment](https://github.com/pytorch/pytorch/pull/172222#issuecomment-3745513973))
- [Revert "Support tensor.backward in dynamo (#169415)"](https://github.com/pytorch/pytorch/commit/1415441ccc03f4f8dcdf6dfce16a5750bc976b2c)
  - Reverted automatically by pytorch's autorevert, to avoid this behaviour add the tag autorevert: disable ([comment](https://github.com/pytorch/pytorch/pull/169415#issuecomment-3739320884))

### GHFirst (28)

- [Revert "[Inductor] [Blackwell] Refactor Epilogue subtiling to allow generic subtiling (#172234)"](https://github.com/pytorch/pytorch/commit/53671bed71c1b7d28182c47d7aba6c3557e9f93f)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/172234#issuecomment-3764157174))
- [Revert "Implement MKLGenerator  (#151218)"](https://github.com/pytorch/pytorch/commit/188cad96d40fcaba8f5d6adcb4ad8eafd57f57a9)
  - sorry, it breaks internal test. error:fbcode/caffe2/aten/src/ATen/CPUGeneratorImpl.cpp:8:10: fatal error: 'ATen/mklrng/MKLGeneratorImpl.h' file not found ([comment](https://github.com/pytorch/pytorch/pull/151218#issuecomment-3761997088))
- [Revert "[pytorch][PR] reland D89141291 add fused compute_grad_weight kernel when segments are few but large (#172454)"](https://github.com/pytorch/pytorch/commit/071bbf6855994e23a9039b95464d54fbe158060c)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/172454#issuecomment-3761433261))
- [Revert "option to disable ftz in triton (#167696)"](https://github.com/pytorch/pytorch/commit/1a63385fd8f00c28092e37c6001f12bea32a8c4e)
  - sorry, the imported diff has merge conflict internally, please fix it and reland ([comment](https://github.com/pytorch/pytorch/pull/167696#issuecomment-3760969476))
- [Revert "[inductor] Use custom triton kernel subclass when available (#167456)"](https://github.com/pytorch/pytorch/commit/1c3a363e8db832bcb0ba40665bb01da5c7c23c67)
  - sorry, a previous commit have issues to land internally, please rebase and try again ([comment](https://github.com/pytorch/pytorch/pull/167456#issuecomment-3760955717))
- [Revert "[xpu][static_launcher] 2/4: Refactor static cuda launcher to static triton launcher. (#169121)"](https://github.com/pytorch/pytorch/commit/a01bb47a0ccc19bcfb8145ea50f625808f928ddf)
  - break internal system, and casued SEV, please reachout internal staff for more details ([comment](https://github.com/pytorch/pytorch/pull/169121#issuecomment-3760882742))
- [Revert "[xpu][feature][static_launcher] 3/4: Add xpu static launcher cpp module. (#168952)"](https://github.com/pytorch/pytorch/commit/681d49c234a87cea0869dfa419c547675f1ada76)
  - break internal system, and casued SEV, please reachout internal staff for more details ([comment](https://github.com/pytorch/pytorch/pull/169121#issuecomment-3760882742))
- [Revert "[xpu][feature][static_launcher] 4/4: Enable static triton kernel launcher for XPU backend. (#169938)"](https://github.com/pytorch/pytorch/commit/f309c1b4a68e0b265533a41d47f40117c9a65d2b)
  - the bottom stack break internal system, and casued SEV, please reachout internal staff for more details ([comment](https://github.com/pytorch/pytorch/pull/169938#issuecomment-3760852148))
- [Revert "[ROCm] Enable StaticTritonLauncher for ROCm (#166492)"](https://github.com/pytorch/pytorch/commit/ff8dd55e0dd146cfa4b36603e107d5c01971151a)
  - sorry, a previous commit introduce the new test file breaks internal system, please rebase after https://github.com/pytorch/pytorch/pull/169121 's revert and reland ([comment](https://github.com/pytorch/pytorch/pull/166492#issuecomment-3760844167))
- [Revert "explicit dynamic shapes maps namings (#172405)"](https://github.com/pytorch/pytorch/commit/68286ac42cbf68e3eb9607874e9eabb09f841bd7)
  - sorry but it seems like this breaks internal test, error: AttributeError: 'ShapeEnv' object has no attribute 'var_to_val'. Did you mean: 'val_to_var'? ([comment](https://github.com/pytorch/pytorch/pull/172405#issuecomment-3760701401))
- [Revert "remove override hint from size_hint, atomically_size_hint, and symbolic_hint (#172429)"](https://github.com/pytorch/pytorch/commit/6cc9de061e30b4101ad530554a901db95762fdf8)
  - sorry but it seems like this breaks internal test, error: AttributeError: 'ShapeEnv' object has no attribute 'var_to_val'. Did you mean: 'val_to_var'? ([comment](https://github.com/pytorch/pytorch/pull/172405#issuecomment-3760701401))
- [Revert "[BE]: Update frozen metautils dataclasses to use slots (#172173)"](https://github.com/pytorch/pytorch/commit/9fcc7856ce532e5c5807ae3ba8e7e05c88e826b8)
  - it breaks internal test after landed, please ask internal staff to help to debug, see more test details in https://www.internalfb.com/phabricator/paste/view/P2127092829  ([comment](https://github.com/pytorch/pytorch/pull/172173#issuecomment-3757294927))
- [Revert "[Inductor] Add fma lowerings for addcmul ops (#170531)"](https://github.com/pytorch/pytorch/commit/6922a53f48aa60bb3031aba131ee23a8aeac437f)
  - sorry it seems failed the internal tests, please see D90691463 for more details ([comment](https://github.com/pytorch/pytorch/pull/170531#issuecomment-3755972691))
- [Revert "[Inductor] Ensure combo kernels respect FMA settings (#170532)"](https://github.com/pytorch/pytorch/commit/818aabeb72b3337b6c2024c69e39bf1f46bcb7b4)
  - sorry it seems failed the internal tests, please see D90691463 for more details ([comment](https://github.com/pytorch/pytorch/pull/170531#issuecomment-3755972691))
- [Revert "[xpu][test] Port distributed checkpoint test cases on Intel GPU (#168921)"](https://github.com/pytorch/pytorch/commit/56ddebf65feea0bdd9cc4fbfa4efac511715cb07)
  - sorry but seems like this break internal tests  dlrm/tests/amd:aps_dlrm_local_model_publish_test_on_amd due to AttributeError: partially initialized module 'triton' has no attribute 'language' (most likely due to a circular import)  ([comment](https://github.com/pytorch/pytorch/pull/168921#issuecomment-3755755311))
- [Revert "[dynamo] Fix property setter on nested MutableMapping objects (#172001)"](https://github.com/pytorch/pytorch/commit/e040897dcb90a8e4c7b19e0b89eaf8eb69cffe7e)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/172001#issuecomment-3752832257))
- [Revert "[BE][Ez]: Misc enablement of slots on frozen dataclasses (#172346)"](https://github.com/pytorch/pytorch/commit/8fb088f2b9d448df64e9e799043ca2b1b59378c7)
  - sorry it seems your change may break internal tests, error example: undefined symbol: cuCtxGetCurrent, please find internal staff for more investigation ([comment](https://github.com/pytorch/pytorch/pull/172346#issuecomment-3751884616))
- [Revert "[SymmMem] Back symm_mem.emtpy() with implicit pool (#172292)"](https://github.com/pytorch/pytorch/commit/ee562d97dfdc683ade44a4883741c6b4005ecef3)
  - sorry but it seems your pr failed internal test. error: torch._inductor.exc.InductorError: ImportError: undefined symbol: cuCtxGetCurrent, please reach out intenral staff for further debugging ([comment](https://github.com/pytorch/pytorch/pull/172292#issuecomment-3750623739))
- [Revert "[ROCm] Optimize single-block TopK with warp-level compaction (#171940)"](https://github.com/pytorch/pytorch/commit/e5e6b08051e961d04f0cdfdad7ccf235dce3e250)
  - sorry this breaks internal tests, [D90544786](https://www.internalfb.com/diff/D90544786), use of undeclared identifier '__syncwarp'; did you mean '__sync_swap'? ([comment](https://github.com/pytorch/pytorch/pull/171940#issuecomment-3745632503))
- [Revert "[ROCm] SDPA fix mem fault when dropout is enabled (#154864)"](https://github.com/pytorch/pytorch/commit/1aa99d6064111f5d38bce5da7dfe6dfb14a01796)
  - already unland internally since it's broken internal tests, ticket: T251298521 ([comment](https://github.com/pytorch/pytorch/pull/154864#issuecomment-3745570638))
- [Revert "Clean up existing pyrefly errors on main (#172251)"](https://github.com/pytorch/pytorch/commit/4a3dc6f7c7e1970e4c27baa5c5dc56b5fc02cb34)
  - sorry, we run into issue to revert another pr which conflict with this, please rebase this after https://github.com/pytorch/pytorch/pull/154864 and reland again ([comment](https://github.com/pytorch/pytorch/pull/172251#issuecomment-3745560625))
- [Revert "[xpu][feature] Introduce a new API torch.xpu._dumpp_snapshot (#170186)"](https://github.com/pytorch/pytorch/commit/1c3e695f1986a14a1eeb85b0ff586196441aff2b)
  - _Snapshot type definition does not contain all fields returned by _cuda_memorySnapshot, we probably want to include all to avoid breaking more strict type checks, like internal ones ([comment](https://github.com/pytorch/pytorch/pull/170186#issuecomment-3737178523))
- [Revert "Support mix BigInt and Number for MemoryViz (#170645)"](https://github.com/pytorch/pytorch/commit/9eb15381ef8b1d975da09052e055ebfa2f7baa58)
  - _Snapshot type definition does not contain all fields returned by _cuda_memorySnapshot, we probably want to include all to avoid breaking more strict type checks, like internal ones ([comment](https://github.com/pytorch/pytorch/pull/170186#issuecomment-3737178523))
- [Revert "[coor-slicing] Factor out DeviceMesh._compute_coordinates_from_mesh (#169549)"](https://github.com/pytorch/pytorch/commit/01c52beccfb54210aacd8ecdc144539b254fb657)
  - seems to be breaking internal signals, see D90448078 ([comment](https://github.com/pytorch/pytorch/pull/169549#issuecomment-3737129229))
- [Revert "[coor-slicing] extract _get_mesh_tensor_from_full_mesh (#169550)"](https://github.com/pytorch/pytorch/commit/732ad91df113d2e1b344924b44ff236039892033)
  - seems to be breaking internal signals, see D90448078 ([comment](https://github.com/pytorch/pytorch/pull/169550#issuecomment-3737111113))
- [Revert "[coor-slicing] _select_split_tensor (#169551)"](https://github.com/pytorch/pytorch/commit/7363a1cae3681131f2f5fcbe2b579a697bf3a534)
  - seems to be breaking internal signals, see D90448078 ([comment](https://github.com/pytorch/pytorch/pull/169551#issuecomment-3737106097))
- [Revert "[Inductor] Add fma lowerings for addcmul ops (#170531)"](https://github.com/pytorch/pytorch/commit/ab670203f88405f766c9d7fc0180ef6ab1d8b72a)
  - seems to break internal signals, see D90440132 ([comment](https://github.com/pytorch/pytorch/pull/170531#issuecomment-3737088773))
- [Revert "[Inductor] Ensure combo kernels respect FMA settings (#170532)"](https://github.com/pytorch/pytorch/commit/8091c96b93ab5a0f42748ea7b1ba01c58728e38b)
  - seems to break internal signals, see D90440132 ([comment](https://github.com/pytorch/pytorch/pull/170531#issuecomment-3737088773))

### Landrace (1)

- [Revert "[invoke_subgraph] Fix dce_hop_extra_outputs to collect all callers first before pruning (#172506)"](https://github.com/pytorch/pytorch/commit/0e9345d26ed4c15c1d32704a1596fc10a2cf56da)
  - Sorry for reverting your change but the new test is failing in trunk ([comment](https://github.com/pytorch/pytorch/pull/172506#issuecomment-3762789609))

### No Signal (6)

- [Revert "[SymmMem] Add multimem support for NCCL and NVSHMEM (#172185)"](https://github.com/pytorch/pytorch/commit/78702773cbfe8bc9427c805d35dc66fefb67645d)
  - Sorry for reverting the change but I think it is failing vLLM benchmark job ([comment](https://github.com/pytorch/pytorch/pull/172185#issuecomment-3752983984))
- [Revert "[BE] Remove opentelemetry submodule (#172458)"](https://github.com/pytorch/pytorch/commit/5f360e530176295579deb1e6951b266cafb58848)
  - sorry but this breaks the trunk due to alueError: could not identify license file for /Users/ec2-user/runner/_work/pytorch/pytorch/third_party/opentelemetry-cpp/tools/vcpkg/ports/sigslot, see https://hud.pytorch.org/pytorch/pytorch/commit/4c78f40245d03722d1880ceb6a09d2f95712ca57#60406597123-box ([comment](https://github.com/pytorch/pytorch/pull/172458#issuecomment-3752093607))
- [Revert "[dynamo] Support type inspection on unrealized LazyConstantVariables (#169513)"](https://github.com/pytorch/pytorch/commit/18f68ed09eee83cd2be849e54cdc591da3616530)
  - Reverting the whole stack then https://github.com/pytorch/pytorch/pull/170644#issuecomment-3747887069 ([comment](https://github.com/pytorch/pytorch/pull/169513#issuecomment-3749107009))
- [Revert "[dynamo] Support constant ops on unrealized LazyConstantVariables (#170092)"](https://github.com/pytorch/pytorch/commit/65a34a1d1f8345be66be639d7c6f5c1300ab7d19)
  - Reverting the whole stack then https://github.com/pytorch/pytorch/pull/170644#issuecomment-3747887069 ([comment](https://github.com/pytorch/pytorch/pull/169513#issuecomment-3749107009))
- [Revert "[dynamo] Support dict assignment with lazy constant keys (#170644)"](https://github.com/pytorch/pytorch/commit/46924b23603f132e37a0e2a7c1af010dffb3e6ed)
  - Sorry for reverting your change but it seems that one of the diff in the stack is breaking vLLM LoRa tests ([comment](https://github.com/pytorch/pytorch/pull/170644#issuecomment-3747887069))
- [Revert "[SymmMem] Add multimem support for NCCL and NVSHMEM (#172185)"](https://github.com/pytorch/pytorch/commit/4652482bbdfc79fccc6316fe2b17ffba11a0c176)
  - breaking CI builds with new nvshmem. See https://github.com/pytorch/pytorch/issues/172348 ([comment](https://github.com/pytorch/pytorch/pull/172185#issuecomment-3745702331))

### Weird (1)

- [Revert "Change _compute_local_shape_and_global_offset API to be backward-compatible (#172176)"](https://github.com/pytorch/pytorch/commit/b9fefebedf66f3ca8795fcc259189db85ec13a2a)
  - sorry, need to revert in order to revert https://github.com/pytorch/pytorch/pull/169549, please feel free to re-merge this change once rebased ([comment](https://github.com/pytorch/pytorch/pull/172176#issuecomment-3737124363))
