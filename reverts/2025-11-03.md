# Week of 2025-11-03 to 2025-11-10 (34)

### Auto Revert (4)

- [Revert "[BE][Typing][Dynamo] Type torch/_dynamo/variables/functions.py (#167103)"](https://github.com/pytorch/pytorch/commit/cd6d06a22ba3a90f6592da9ffecead7dae54b5f6)
  - Reverted automatically by pytorch's autorevert, to avoid this behaviour add the tag autorevert: disable ([comment](https://github.com/pytorch/pytorch/pull/167103#issuecomment-3500023910))
- [Revert "Avoid DDE in narrow with unbacked start (#166361)"](https://github.com/pytorch/pytorch/commit/c10975d2e661d673b1bcf1a5b8f577f861596088)
  - Reverted automatically by pytorch's autorevert, to avoid this behaviour add the tag autorevert: disable ([comment](https://github.com/pytorch/pytorch/pull/166361#issuecomment-3482194351))
- [Revert "[FSDP][Replicate] final version integrating 1D device mesh replicate into fsdp (#166433)"](https://github.com/pytorch/pytorch/commit/fa0fd6be13c25d8c092045cc0c38ceb5f6fe8072)
  - Reverted automatically by pytorch's autorevert, to avoid this behaviour add the tag autorevert: disable ([comment](https://github.com/pytorch/pytorch/pull/166433#issuecomment-3481929476))
- [Revert "[FSDP][Replicate] added two replicate overload declarations and changed device_mesh to mesh (#166459)"](https://github.com/pytorch/pytorch/commit/2f3f88f445ce291ea9bfa7bf7c832b6a2366b9ea)
  - Reverted automatically by pytorch's autorevert, to avoid this behaviour add the tag autorevert: disable ([comment](https://github.com/pytorch/pytorch/pull/166433#issuecomment-3481929476))

### GHFirst (8)

- [Revert "[CP] Correctly compile create_cp_block_mask (#167153)"](https://github.com/pytorch/pytorch/commit/c131e4b390ae779320c3a069e426b478fab46529)
  - breaking internal tests D86529123 ([comment](https://github.com/pytorch/pytorch/pull/167153#issuecomment-3505563239))
- [Revert "Remove python workaround for ContextDecorator (#167049)"](https://github.com/pytorch/pytorch/commit/bbf852d87ff527a5cdd9b9ca999356062eadf575)
  - breaking internal tests D86342845 ([comment](https://github.com/pytorch/pytorch/pull/167049#issuecomment-3505251296))
- [Revert "[13/N] Apply ruff UP035 rule (#167048)"](https://github.com/pytorch/pytorch/commit/6392b986e7e72dee831696d0bdf543ca9f8609b8)
  - breaking internal tests D86342860 ([comment](https://github.com/pytorch/pytorch/pull/167048#issuecomment-3505232522))
- [Revert "Update pythoncapi_compat.h (#167138)"](https://github.com/pytorch/pytorch/commit/fb9e10fe255732c7ba0590099a85326d5ad51d8e)
  - Sorry but this is breaking internally. See diff D86458778 for details. ([comment](https://github.com/pytorch/pytorch/pull/167138#issuecomment-3504895388))
- [Revert "Don't hardcode double argument for reduction base (#166951)"](https://github.com/pytorch/pytorch/commit/b2d72a4008fa13612adc34c246e8e24c2185300e)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/166951#issuecomment-3497253260))
- [Revert "[DebugMode] output, tensor id annotations for DebugMode (#165076)"](https://github.com/pytorch/pytorch/commit/ef3f953966d94ce11ced06f8e468b2fa69c1b3cb)
  - Sorry but this is breaking internally. See diff [D86245252](https://l.workplace.com/l.php?u=https%3A%2F%2Fwww.internalfb.com%2Fdiff%2FD86245252&h=AT1oPbS1XTv6HjYeYdxmDMW1-jlT0pS8yBO2iSfbPfUB9ydsEjFXBNT56QhV1v5TKc4_QaQNxykNowSKmb4fgenjOyCv20NuL7oV_Id5fhh32hhv1IpjgsDJYK-PBFfSfv_miLIWfNgj902KcgXojbBgDcDzQeS9lNt0GQ) for details. To validate your fixes internally, you can follow the instructions here: https://fburl.com/fixing-ghfirst-reverts ([comment](https://github.com/pytorch/pytorch/pull/165076#issuecomment-3493358159))
- [Revert "[12/N] Apply ruff UP035 rule (#166929)"](https://github.com/pytorch/pytorch/commit/6d30666bc1cad94295f708f74ebaf161e291c273)
  - Temporarily need to revert this to continue a revert for #165076. @cyyever Please re-merge after revert of #165076. ([comment](https://github.com/pytorch/pytorch/pull/166929#issuecomment-3493090596))
- [Revert "Fixes torch.compile(nn.ModuleList()) changes bool() behavior  (#159208)"](https://github.com/pytorch/pytorch/commit/61bcc8d75ad065a40b2d7953046616d5979233b9)
  - Broke internal tests ([comment](https://github.com/pytorch/pytorch/pull/159208#issuecomment-3480743499))

### Ignored Signal (3)

- [Revert "[Inductor] addmm with bias -> unfuse bias if there is a pointwise/reduction consumer (#166165)"](https://github.com/pytorch/pytorch/commit/9b4ac45d2fd7e4bde216efa18d1e8e4bce33e4ae)
  - Breaking internal tests D86216934 ([comment](https://github.com/pytorch/pytorch/pull/166165#issuecomment-3499645688))
- [Revert "[cuDNN] Smoke-test runtime cuDNN version matches compile time version in CI (#165922)"](https://github.com/pytorch/pytorch/commit/ad5c7c20e0dd55baa23a597cf10ffe7422b5cabf)
  - Introduces Segfault in linux-jammy-cuda12.8-py3.10-gcc11 ([comment](https://github.com/pytorch/pytorch/pull/165922#issuecomment-3492667312))
- [Revert "Update triton to 3.5.1 release (#166968)"](https://github.com/pytorch/pytorch/commit/9c2c3dbc156a0eae1212ec3e51109d83a4922c9b)
  - It might have caused deadlock/test timeouts, see https://hud.pytorch.org/hud/pytorch/pytorch/d4dcd0354c4affcd90417f213785fc762e1b2b2f/1?per_page=50&name_filter=trunk%20%2F%20linux-jammy-cuda12.8-py3.10-gcc11%20%2F%20test&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/166968#issuecomment-3492399396))

### Landrace (2)

- [Revert "[ROCm] Enable StaticCudaLauncher for ROCm (#166492)"](https://github.com/pytorch/pytorch/commit/b228f6d180925aee5c60f26dad8e35d12bcaeb6a)
  - test/inductor/test_ck_backend.py::TestCKBackend::test_max_autotune_precompile_matmul_dynamic_max_autotune_gemm_backends_CK_autotune_in_subproc_True [GH job link](https://github.com/pytorch/pytorch/actions/runs/19147453561/job/54731084387) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/ba2e6b0b4f1718767762d7b20558d4de943be71b) ([comment](https://github.com/pytorch/pytorch/pull/166492#issuecomment-3500049276))
- [Revert "Add model code stack trace to torch.profile (#166677)"](https://github.com/pytorch/pytorch/commit/81038fd3268074a43d0b8fc4de9cf22a6d71a896)
  - Broke lint, please rebase, we've moved from mypy to pyrefly ([comment](https://github.com/pytorch/pytorch/pull/166677#issuecomment-3488219996))

### Not through pytorchbot (2)

- [Revert "Back out "Do not decompose in functionalization/proxy tensor if autograd wouldn't have decomposed (#164939)" (#165910)" (#166812)](https://github.com/pytorch/pytorch/commit/76bb27e248750fc558ec4ea9050e09a6f171e9bc)
- [Revert "Back out "Do not decompose in functionalization/proxy tensor if autograd wouldn't have decomposed (#164939)" (#165910)" (#166812)](https://github.com/pytorch/pytorch/commit/5a3930abbc19eac9a179455df82e206e69765ed2)

### No Signal (14)

- [Revert "[Inductor][Grouped Gemm] Add Blackwell CuTeDSL Kernel (#167182)"](https://github.com/pytorch/pytorch/commit/12860892f825d5d8d73c9ea18549dc008f7977a0)
  - breaks local source build ([comment](https://github.com/pytorch/pytorch/pull/167182#issuecomment-3503598156))
- [Revert "Move enrich_profiler_metadata config import out of gm.recompile() (#167114)"](https://github.com/pytorch/pytorch/commit/31ac76423917ddac34c22beb6fbada2955b11f43)
  - broke rocm ([comment](https://github.com/pytorch/pytorch/pull/167114#issuecomment-3500057321))
- [Revert "[Inductor] Fix unbacked float symbol handling in kernel codegen (#166890)"](https://github.com/pytorch/pytorch/commit/8e8cbb85ee927776210f7872e3d0286d5d40dc14)
  - Looks like it broke torchfuzz tests, see https://hud.pytorch.org/hud/pytorch/pytorch/fbd70fb84e347b45db79eb24cc2c53e447a04147/1?per_page=50&name_filter=trunk%20%2F%20linux-jammy-cuda12&mergeEphemeralLF=true and same test on slow ([comment](https://github.com/pytorch/pytorch/pull/166890#issuecomment-3493011038))
- [Revert "Add model code stack trace to torch.profile (#166677)"](https://github.com/pytorch/pytorch/commit/c86540f12038ffc4a3c9ecdbecb01ce73e0967c9)
  - broke rocm ([comment](https://github.com/pytorch/pytorch/pull/166677#issuecomment-3492658160))
- [Revert "[Inductor][Grouped Gemm] Add Blackwell CuTeDSL Kernel (#167003)"](https://github.com/pytorch/pytorch/commit/5c639466f7b1f9453c2a9c0e25b41c3774a12af8)
  - regressed vllm signal: [GH job link](https://github.com/pytorch/pytorch/actions/runs/19093785744/job/54553796743) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/658c5f879c37142b1df51c7eb6c5a5bb06318597) ([comment](https://github.com/pytorch/pytorch/pull/167003#issuecomment-3491527704))
- [Revert "Avoid DDE in narrow with unbacked start (#166361)"](https://github.com/pytorch/pytorch/commit/a743f9eeb57255f800d4c91ba29da6e0d9c4a229)
  - Looks like it broke test_torchfuzz subtests, see https://hud.pytorch.org/hud/pytorch/pytorch/01e6e35c7faf913c3a85c7a64d2939cfa768358a/1?per_page=50&name_filter=trunk&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/166361#issuecomment-3488916766))
- [Revert "[Inductor][Grouped Gemm] Add Blackwell CuTeDSL Kernel (#165036)"](https://github.com/pytorch/pytorch/commit/d77c24caac4b42c56b4fa6a156ce85fb4907643e)
  - regressed vllm signal: [GH job link](https://github.com/pytorch/pytorch/actions/runs/19059329909/job/54439919668) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/0e1a88904f4a5e30634b196678b56e1d6ec074f5) ([comment](https://github.com/pytorch/pytorch/pull/165036#issuecomment-3487846555))
- [Revert "[inductor] require shape in TritonCSEVariable (#162275)"](https://github.com/pytorch/pytorch/commit/d3cf90ada5402a2d61bb90b762c6e8ed86cd3d5a)
  - breaking test_rms_norm_bwd_float32_split_reductions_True_shape2 ([comment](https://github.com/pytorch/pytorch/pull/162275#issuecomment-3484049109))
- [Revert "Fix  unused assignments  (#166791)"](https://github.com/pytorch/pytorch/commit/79ff2c66c88ad76b09460a11d949d71155e67b34)
  - incomplete PR ([comment](https://github.com/pytorch/pytorch/pull/166791#issuecomment-3483116247))
- [Revert "[CUDA] Skip pynvml test on platforms that don't have complete support (#159689)"](https://github.com/pytorch/pytorch/commit/665a4113517e5802aeeb729f9b26cedd31a3acf2)
  - breaking internal tests [D86127316] ([comment](https://github.com/pytorch/pytorch/pull/159689#issuecomment-3483095879))
- [Revert "[Inductor] addmm with bias -> unfuse bias if there is a pointwise/reduction consumer (#166165)"](https://github.com/pytorch/pytorch/commit/86b2d82e84898575a18f4859821a2ed5dc0d458f)
  - breaks test_LinearAndSoftmax_codegen test ([comment](https://github.com/pytorch/pytorch/pull/166165#issuecomment-3482926991))
- [Revert "[MPS] Fix `smooth_l1_loss` backward for fp16 (#166687)"](https://github.com/pytorch/pytorch/commit/1656b253c5fcc34a53a9991303170892c6d90c1d)
  - [GH job link](https://github.com/pytorch/pytorch/actions/runs/19027214755/job/54332952760) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/95ab09cb54f6ba13eda0160b663e85119f68ac14) ([comment](https://github.com/pytorch/pytorch/pull/166687#issuecomment-3480694316))
- [Revert "Give full Dynamo stack traces in CI (#160417)"](https://github.com/pytorch/pytorch/commit/5d6230779d920e9c449c22d22fd0f69fe7b73632)
  - test/dynamo/test_aot_compile.py::TestAOTCompile::test_aot_compile_graph_break_error_fmt [GH job link](https://github.com/pytorch/pytorch/actions/runs/19028849833/job/54339349886) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/e0791fc11dc0024a828495985898b29120dcc4c1) ([comment](https://github.com/pytorch/pytorch/pull/160417#issuecomment-3480680049))
- [Revert "[MPS] Error out when BatchNorm is called for Complex (#166215)"](https://github.com/pytorch/pytorch/commit/a4077b568f891f8cad948cc70cbb14043791d762)
  - sorry need to revert https://github.com/pytorch/pytorch/pull/166687 ([comment](https://github.com/pytorch/pytorch/pull/166215#issuecomment-3480661671))

### Weird (1)

- [Revert "make narrow_tensor_symint DDE-free (#166379)"](https://github.com/pytorch/pytorch/commit/53b03f1a2b4c8fc0e20bdff4cfbb43aad01bb978)
  - Need to revert previous PR in the stack ([comment](https://github.com/pytorch/pytorch/pull/166379#issuecomment-3488910172))
