# Week of 2025-11-17 to 2025-11-24 (40)

### Auto Revert (2)

- [Revert "Change NamedTupleVariable implementation to subclass UserDefinedTupleVariable (#167468)"](https://github.com/pytorch/pytorch/commit/7a064ed3eafa43f17412d434b395240c727b3000)
  - Reverted automatically by pytorch's autorevert, to avoid this behaviour add the tag autorevert: disable ([comment](https://github.com/pytorch/pytorch/pull/167468#issuecomment-3555613000))
- [Revert "[ROCm][CI] Upgrade ROCm CI to 7.1 (#166743)"](https://github.com/pytorch/pytorch/commit/694f9b943c12c02c6907c5aa19177865895b81ab)
  - Reverted automatically by pytorch's autorevert, to avoid this behaviour add the tag autorevert: disable ([comment](https://github.com/pytorch/pytorch/pull/166743#issuecomment-3543307333))

### GHFirst (22)

- [Revert "[dynamo] add torch._dynamo.set_recursion_limit to fix 3.12/3.13 RecursionError problems (#167888)"](https://github.com/pytorch/pytorch/commit/4fd97b460cdf7aeebe9f886d1bb55486dfce5006)
  - failed interal test Tracing payload for Mock should not be called: pt2_compile_chromium_events Fatal Python error: Segmentation fault, please remerge after fixing it ([comment](https://github.com/pytorch/pytorch/pull/167888#issuecomment-3567252753))
- [Revert "[inductor] Use custom triton kernel subclass when available (#167456)"](https://github.com/pytorch/pytorch/commit/1f34961aa9828dc442468da7afcd83587b84d594)
  - failed internal test Diff D87660150 , errorl ModuleNotFoundError: No module named 'extension_backends' ([comment](https://github.com/pytorch/pytorch/pull/167456#issuecomment-3567247490))
- [Revert "[Inductor XPU GEMM] Step 1/N: Refactor cutlass configuration. (#160174)"](https://github.com/pytorch/pytorch/commit/3f0d46c8b0035a9c17419601ed7412d294f2c56f)
  - failed internal tests test_cpu_/test_cpu#link-tree/torch/utils/_config_module.py line 371, in _config = self._config[name] KeyError: 'cuda.cutlass_dir' Diff: D87660662 ([comment](https://github.com/pytorch/pytorch/pull/160174#issuecomment-3567237578))
- [Revert "[Inductor XPU GEMM] Step 2/N: Move out cutlass files from torch/_inductor/codegen/cuda (#160685)"](https://github.com/pytorch/pytorch/commit/2c204e6dfc98328ca64beaca4ec49810141809e5)
  - failed internal tests test_cpu_/test_cpu#link-tree/torch/utils/_config_module.py line 371, in _config = self._config[name] KeyError: 'cuda.cutlass_dir' Diff: D87660662 ([comment](https://github.com/pytorch/pytorch/pull/160174#issuecomment-3567237578))
- [Revert "[Full Inductor][Pytorch] Prevent decomposition and enable fallback of aten.native_layer_norm for MTIA (#168290)"](https://github.com/pytorch/pytorch/commit/c23a90041e451b7347d1e587b45188927ee66b89)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/168290#issuecomment-3563174857))
- [Revert "conv: refactor for lookup table support (#167179)"](https://github.com/pytorch/pytorch/commit/05b11198fd4781f0c223c5b6e7dee054858a4d1d)
  - internall error:  expected `Optional[Dict[str, Union[Sequence[Union[bool, float, int]], bool, float, int]]]` but got `Optional[Dict[str, Union[float, int]]]` ([comment](https://github.com/pytorch/pytorch/pull/167179#issuecomment-3560397543))
- [Revert "Improve build logic in activities for kineto (#167204)"](https://github.com/pytorch/pytorch/commit/6edf2aa8f3a694077519e6223f7e132a2071f357)
  - break xpu legacy profiler ([comment](https://github.com/pytorch/pytorch/pull/167204#issuecomment-3558053023))
- [Revert "[AOTI] Fix a GPU memory leak caused by reference circle (#168063)"](https://github.com/pytorch/pytorch/commit/192b96e42b82b8e61bccef1c389e1f03a3c58356)
  - Internal test breaks, contacted author to revert it and fix it test_codegen_int_array_var_fix_memory_leak, self.assertTrue(allocated_memory[1] == allocated_memory[2]) AssertionError: False is not true ([comment](https://github.com/pytorch/pytorch/pull/168063#issuecomment-3555419672))
- [Revert "dist: add list_keys to Store API (#167883)"](https://github.com/pytorch/pytorch/commit/f890837d979a9e9fb59fdd5bff3d3f1857278126)
  - break some internal test,  error: use of undeclared identifier, reached out author but no resp, so revert this to keep diff train hygiene ([comment](https://github.com/pytorch/pytorch/pull/167883#issuecomment-3555212038))
- [Revert "[inductor] fix the decision of inner reduction (#167697)"](https://github.com/pytorch/pytorch/commit/771be8c062abe71fcf77cfdc02e5fd8197bdb041)
  - break internal tests, need to include internal changes ([comment](https://github.com/pytorch/pytorch/pull/167697#issuecomment-3555203239))
- [Revert "[hoo] Invoke subgraph + effect (#167231)"](https://github.com/pytorch/pytorch/commit/ca6175c8f0acb7fea3c5cd088fc55409ba03567f)
  - the diff breaks tests internally  ([comment](https://github.com/pytorch/pytorch/pull/167231#issuecomment-3555183647))
- [Revert "[invoke_subgraph] Don't run the graph twice when autograd enabled (#167245)"](https://github.com/pytorch/pytorch/commit/a6bfe2dedaa6655e7558e52e2b760936615828ff)
  - the base pr is broken  internal tests in the stack ([comment](https://github.com/pytorch/pytorch/pull/167245#issuecomment-3555175850))
- [Revert "[pytree][compile] Slightly faster TreeSpec init (#168024)"](https://github.com/pytorch/pytorch/commit/c7cf3fb12504a3b7f40b2543bf4d511d64f29a11)
  - Internal merge fail, These changes have conflicts when merging with master branch. Rebase this diff. please rebase the pr and try merge again ([comment](https://github.com/pytorch/pytorch/pull/168024#issuecomment-3553015987))
- [Revert "[SymmMem] Skip multicast init if any CUDA call fails (#168049)"](https://github.com/pytorch/pytorch/commit/5abb7bf8fee800e92028e57ebbb41e2e9f62d499)
  - D87346992 internal error that conflict the main branch, please rebase and try to merge again These changes have conflicts when merging with master branch. Rebase this diff. ([comment](https://github.com/pytorch/pytorch/pull/168049#issuecomment-3552985895))
- [Revert "[ROCm] enable fastSpecializedAtomicAdd for gfx950 (#167661)"](https://github.com/pytorch/pytorch/commit/d91269e8ce309437c1f849b5ab3362d69b178ef4)
  - break internal tests and build, please reach out meta fellas to have fix it and reland again, error examplke: hip/KernelUtils.cuh:74:5: error: no matching function for call to 'unsafeAtomicAdd' ([comment](https://github.com/pytorch/pytorch/pull/167661#issuecomment-3548737051))
- [Revert "deprecate check_is_size and guard_size_oblivious (#167198)"](https://github.com/pytorch/pytorch/commit/b7208877c8ce470d1b6170a9b89ff7b4d611710d)
  - synced with author, this breaks internal builds ([comment](https://github.com/pytorch/pytorch/pull/167198#issuecomment-3544065659))
- [Revert "Remove old NVTX interface (#167637)"](https://github.com/pytorch/pytorch/commit/661fb534494e88da84d025ee3da2ca362b81bfcd)
  - breaks internal build with torch/csrc/profiler/stubs/cuda.cpp:4:10: fatal error: 'nvtx3/nvtx3.hpp' file not found 4 | #include <nvtx3/nvtx3.hpp>, please find a meta fella to resolve this issue and try again, diff:[D87229660] ([comment](https://github.com/pytorch/pytorch/pull/167637#issuecomment-3543984021))
- [Revert "[ROCm] Enable StaticCudaLauncher for ROCm (#166492)"](https://github.com/pytorch/pytorch/commit/ae3ce54f27adfc5b580cc08be0690f4a595f2a61)
  - Internally we still depends on the old logic, so we need to find a way to maintain backwards compatibility, for now ([comment](https://github.com/pytorch/pytorch/pull/166492#issuecomment-3543198811))
- [Revert "Use c10::filesystem (#167821)"](https://github.com/pytorch/pytorch/commit/a4c7bf7e8ddde51b2c4e53bb6e7c8985b59cfec0)
  - Breaks internal tests, see D87148810. @Skylion007 may you help the author to get this PR merged? ([comment](https://github.com/pytorch/pytorch/pull/167821#issuecomment-3542877623))
- [Revert "Improve char printing (#167899)"](https://github.com/pytorch/pytorch/commit/22ccd44d732100a301a4f9c9119850682aff48bb)
  - need to revert in order to revert https://github.com/pytorch/pytorch/pull/167899 ([comment](https://github.com/pytorch/pytorch/pull/167899#issuecomment-3542869096))
- [Revert "Remove python workaround for ContextDecorator (#167049)"](https://github.com/pytorch/pytorch/commit/39ebab1dd9e52f363aa076a48aea3a63253f70c7)
  - breaks internal tests see D87120562, @Skylion007 please thelp the author get this PR merged ([comment](https://github.com/pytorch/pytorch/pull/167049#issuecomment-3542847796))
- [Revert "add device generalization support for distributed tests (#165067)"](https://github.com/pytorch/pytorch/commit/4c152a71add2bd6a5f35dd9bb78ebb22e0748357)
  - breaks internal tests see D87036515, @albanD please help the author get this PR merged ([comment](https://github.com/pytorch/pytorch/pull/165067#issuecomment-3542820651))

### Not through pytorchbot (4)

- [Revert #154859 (#168297)](https://github.com/pytorch/pytorch/commit/b1cd563cf8d63924325f9470406fdc15d35c98e0)
- [Revert #168264 + Python-side LRU cache when native op schema is not supported (#168269)](https://github.com/pytorch/pytorch/commit/d4de871adfac825e12bae9068e1c8433bd58455d)
- [Revert #154859 (#168297)](https://github.com/pytorch/pytorch/commit/6707dc8e444de405401f2e36e2868a19bb7ba43a)
- [Revert C++ fastpath dispatch path for DTensor (#168264)](https://github.com/pytorch/pytorch/commit/8ad78bbc2b9c3606f05b882d3e7563c3dd6c8b88)

### No Signal (10)

- [Revert "Revert #154859 (#168297)"](https://github.com/pytorch/pytorch/commit/28656727473a6361ee0ebfa5f412746807343651)
  - this seems breaks the trunk ##[error]Process completed with exit code 2. ([comment](https://github.com/pytorch/pytorch/pull/168297#issuecomment-3561558790))
- [Revert "Remove useless super() delegation (#168235)"](https://github.com/pytorch/pytorch/commit/e7a85200da063a6dc6df0a3554e9e3c2426d0491)
  - breaks distributed tests related to error_pid https://github.com/pytorch/pytorch/actions/runs/19546407616/job/55967118407#step:27:3191 ([comment](https://github.com/pytorch/pytorch/pull/168235#issuecomment-3560268701))
- [Revert "Allow BlockDescriptorOptions classes to be overridden In TritonKernel (#165899)"](https://github.com/pytorch/pytorch/commit/f7fc6346b0d06ecd77b3e905328c57766b4474ea)
  - See #167892 ([comment](https://github.com/pytorch/pytorch/pull/165899#issuecomment-3560236176))
- [Revert "[dynamo][compile time] Special case for torch.utils._pytree._get_node_type (#168054)"](https://github.com/pytorch/pytorch/commit/9396e69194e8e16801b08b1326e34708a859fa5f)
  - failed at D87489130 ([comment](https://github.com/pytorch/pytorch/pull/168054#issuecomment-3559399563))
- [Revert "[dynamo][pytree][compile time] Specialize tree_is_leaf (#168070)"](https://github.com/pytorch/pytorch/commit/803d94be29621ca07e1432af85e41ad240817fd8)
  - failed at D87489130 ([comment](https://github.com/pytorch/pytorch/pull/168054#issuecomment-3559399563))
- [Revert "Hide all symbols (except stable/headeronly/shim) if TORCH_STABLE_ONLY is defined (#167496)"](https://github.com/pytorch/pytorch/commit/acf5b204b033fa65deaa69ff127543412087a185)
  - Failing validations - https://github.com/pytorch/test-infra/actions/runs/19513141127/job/55857898996 ([comment](https://github.com/pytorch/pytorch/pull/167496#issuecomment-3554287955))
- [Revert "Error when non stable/headeronly/shim headers are included by stable extension (#167855)"](https://github.com/pytorch/pytorch/commit/a097e166db7077f1e8da94757ccd91a6a521550e)
  - Failing validations ([comment](https://github.com/pytorch/pytorch/pull/167855#issuecomment-3553987894))
- [Revert "[CD] [aarch64] unify the build.sh to build for aarch64 wheel (#166044)"](https://github.com/pytorch/pytorch/commit/9b39276255a664b6683aa0edc3bae091e01dfb60)
  - Causing https://github.com/pytorch/pytorch/issues/168003 also failing nightly aarch64 cuda validations [pytorch/test-infra/actions/runs/19435158072/job/55604045681](https://github.com/pytorch/test-infra/actions/runs/19435158072/job/55604045681) ([comment](https://github.com/pytorch/pytorch/pull/166044#issuecomment-3544309072))
- [Revert "[CD] Add libopenblas to dep list for AArch64+CPU whl (#167841)"](https://github.com/pytorch/pytorch/commit/86f9a9ae762eb6a7ea44009dd8d64c43fce73977)
  - Will be reverting https://github.com/pytorch/pytorch/pull/166044 ([comment](https://github.com/pytorch/pytorch/pull/167841#issuecomment-3544301008))
- [Revert "[ATen][CUDA] Add sm_121a flag for RowwiseScaledMM (#167734)"](https://github.com/pytorch/pytorch/commit/b9bccec3bc903de51f696214c3a79096639d9002)
  - fails on CUDA 12.8 ([comment](https://github.com/pytorch/pytorch/pull/167734#issuecomment-3540410067))

### Weird (2)

- [Revert "Tiling bug fix (#167771)"](https://github.com/pytorch/pytorch/commit/1c04a4395955590b211d090d394e5b1d98139151)
  - needs one fix ([comment](https://github.com/pytorch/pytorch/pull/167771#issuecomment-3543999822))
- [Revert "[ARM] Improve LLM performance & mem usage using int4-bf16 KleidiAI kernels (#158250)"](https://github.com/pytorch/pytorch/commit/9d8ceaa36f085410f3712a6101efbb5b423f7da0)
  - reverting to see if it fixes inductor halide test failure ([comment](https://github.com/pytorch/pytorch/pull/158250#issuecomment-3543840277))
